# 生成AI下調べ帳
生成AIについて、ソフトウェアエンジニア視点で下記のような問いを立てた。急速に進歩している分野で、全てに完全な答えを出すことはできないだろうが、おおよその見通しが立てられるよう、下調べをしておく。

- 生成AIの仕組みは？
    - Transformerの仕組み
    - 何がイノベーションを起こしたのか
        - Self Attention
        - 事前学習（Pre-training）と事後学習（Post-Training）
        - Scaling Laws
        - ハードウェアの進化
    - GPTの仕組み
        - GPT, GPT-2, GPT-3のモデル
        - 事前学習（Pre-training）の仕方
        - 事後学習（Post-Training）の仕方
    - マルチモーダルの仕組み
- 生成AIの使い方は？
    - 代表的なモデルとできること
    - 生成AIが得意なタスク
    - 主な使い方
        - プロンプトエンジニアリング
            - zero-shot, few-shot
            - Chaing-of-Thought
            - Tree-of-Thoughts
            - Generate Knowledge Prompting
            - Directional Stimulus Prompting
        - 設計パターン
            - 生成AI＋検索
            - 生成AI＋Agent
            - 生成AI＋コード実行
        - embedding
        - fine-tuning
    - 性能評価
        - モデルのベンチマーク
        - 下流タスクの性能評価
    - 生成AIシステムの運用
    - リスク管理
- 生成AIとどう関わっていけばいいのか？
    - 関わり方のパターンの整理
    - ソフトウェア（SaaS）業界がどう変わるか？
    - 上記を受けて、個人的にはどう考えるか？
- 開発業務でどう活用するか？
    - github copilot
        - セットアップ
        - 実装
        - ドキュメント作成
    - github copilot chat
        - セットアップ
        - コード生成
        - テストコード生成
        - デバッグ
        - レビューリファクタリング
        - コード変換
    - OpenAIのAPI
- 顧客にどういう価値を提供できるか？
- その他、個別に深堀りしたいトピック
    - [教材・学習コンテンツ](https://zenn.dev/akira_isegawa/scraps/0647e25a97b140)
    - [日本語LLM](https://zenn.dev/akira_isegawa/scraps/11c64e03d14453)
    - データセット
        - [QAタスクの日本語データセット](https://zenn.dev/akira_isegawa/scraps/64f0d72fbc314c)
    - [フレームワーク（LangChain、LlamaIndex、Haystack等）](https://zenn.dev/akira_isegawa/scraps/b081468031d6f5)
    - [Retrieval Augumented Generation(RAG)](https://zenn.dev/akira_isegawa/scraps/e32fccba758fbc)
    - [Program-Aided Language Models(PAL)](https://zenn.dev/akira_isegawa/scraps/c10976a217cdd9)
    - 自律型AIエンジニア
    - Transformerの次は？
        - Transformer以前の歴史
        - 改善の方向性（大規模化？軽量化？ドメイン特化？）
        - Transformerの後継モデルは？


